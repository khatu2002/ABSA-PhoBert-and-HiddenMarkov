{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aspect_and_sentiment(file_path, output_file_path):\n",
    "    processed_data = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Xử lý từng nhóm 3 dòng: câu, khía cạnh, sentiment\n",
    "        for i in range(0, len(lines), 3):\n",
    "            sentence = lines[i].strip()\n",
    "            aspect = lines[i+1].strip()\n",
    "            sentiment = lines[i+2].strip()\n",
    "            \n",
    "            # Thay thế $T$ bằng khía cạnh và thêm token đặc biệt\n",
    "            marked_sentence = sentence.replace('$T$', f\"<aspect> {aspect} </aspect>\")\n",
    "            \n",
    "            # Kết hợp câu đã đánh dấu với khía cạnh và sentiment\n",
    "            processed_data.append(f\"{marked_sentence}\\t{aspect}\\t{sentiment}\")\n",
    "    \n",
    "    # Lưu dữ liệu đã xử lý vào file mới\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        for line in processed_data:\n",
    "            output_file.write(line + '\\n')\n",
    "\n",
    "# Gọi hàm để xử lý file train và test\n",
    "process_aspect_and_sentiment('train.raw', 'final_processed_train.tsv')\n",
    "process_aspect_and_sentiment('test.raw', 'final_processed_test.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Hàm để loại bỏ các ký tự không phù hợp mà vẫn giữ token đặc biệt như <aspect> và </aspect>\n",
    "def remove_unwanted_characters(sentence):\n",
    "    # Loại bỏ ký tự đặc biệt như *** và hashtag\n",
    "    sentence = re.sub(r\"\\*+\", \"\", sentence)  # Loại bỏ ký tự *\n",
    "    sentence = re.sub(r\"#\\S+\", \"\", sentence)  # Loại bỏ hashtag\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)  # Loại bỏ URL\n",
    "    # Loại bỏ các ký tự không phải là chữ cái, số, dấu câu, hoặc các token đặc biệt <aspect> </aspect>\n",
    "    sentence = re.sub(r\"[^\\w\\s,.!?:;<>/]\", \"\", sentence)\n",
    "    return sentence\n",
    "\n",
    "# Hàm xử lý toàn bộ dataset chỉ loại bỏ ký tự không phù hợp\n",
    "def process_dataset_remove_unwanted(file_path, output_file_path):\n",
    "    cleaned_data = []\n",
    "    \n",
    "    # Đọc dữ liệu từ file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) == 3:\n",
    "            sentence, aspect, sentiment = parts\n",
    "            # Loại bỏ ký tự không phù hợp trong câu văn bản và khía cạnh\n",
    "            cleaned_sentence = remove_unwanted_characters(sentence)\n",
    "            cleaned_aspect = remove_unwanted_characters(aspect)\n",
    "            cleaned_data.append(f\"{cleaned_sentence}\\t{cleaned_aspect}\\t{sentiment}\")\n",
    "    \n",
    "    # Lưu dữ liệu đã làm sạch vào file mới\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        for line in cleaned_data:\n",
    "            output_file.write(line + '\\n')\n",
    "\n",
    "# Gọi hàm để xử lý và lưu file\n",
    "process_dataset_remove_unwanted('final_processed_train.tsv', 'cleaned_final_processed_train.tsv')\n",
    "process_dataset_remove_unwanted('final_processed_test.tsv', 'cleaned_final_processed_test.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xử lý hoàn tất, file đã được lưu.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Hàm để loại bỏ dấu chấm trong khía cạnh (aspect)\n",
    "def remove_period_from_aspect(aspect):\n",
    "    # Loại bỏ dấu chấm ở đầu, cuối, và giữa khía cạnh\n",
    "    return aspect.replace('.', '')\n",
    "\n",
    "# Hàm xử lý toàn bộ dataset để loại bỏ dấu chấm trong khía cạnh\n",
    "def process_dataset_remove_period(file_path, output_file_path):\n",
    "    cleaned_data = []\n",
    "    \n",
    "    # Đọc dữ liệu từ file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Xử lý từng dòng dữ liệu\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) == 3:\n",
    "            sentence, aspect, sentiment = parts\n",
    "            # Loại bỏ dấu chấm trong khía cạnh\n",
    "            cleaned_aspect = remove_period_from_aspect(aspect)\n",
    "            cleaned_data.append(f\"{sentence}\\t{cleaned_aspect}\\t{sentiment}\")\n",
    "    \n",
    "    # Lưu dữ liệu đã làm sạch vào file mới\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        for line in cleaned_data:\n",
    "            output_file.write(line + '\\n')\n",
    "\n",
    "# Gọi hàm để xử lý file train và test\n",
    "process_dataset_remove_period('cleaned_final_processed_train.tsv', 'cleaned_final_processed_train_no_period.tsv')\n",
    "process_dataset_remove_period('cleaned_final_processed_test.tsv', 'cleaned_final_processed_test_no_period.tsv')\n",
    "\n",
    "print(\"Xử lý hoàn tất, file đã được lưu.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file train và test\n",
    "train_data = pd.read_csv('train_final.tsv', sep='\\t', header=None, names=['sentence', 'aspect', 'sentiment'])\n",
    "test_data = pd.read_csv('test_final.tsv', sep='\\t', header=None, names=['sentence', 'aspect', 'sentiment'])\n",
    "\n",
    "# Thay đổi các giá trị sentiment:\n",
    "# - `-1` (tiêu cực) sẽ thành `0`\n",
    "# - `0` (trung lập) sẽ thành `1`\n",
    "# - `1` (tích cực) sẽ thành `2`\n",
    "train_data['sentiment'] = train_data['sentiment'].map({-1: 0, 0: 1, 1: 2})\n",
    "test_data['sentiment'] = test_data['sentiment'].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# Lưu lại file đã chỉnh sửa\n",
    "train_data.to_csv('train_final_fixed.tsv', sep='\\t', index=False, header=False)\n",
    "test_data.to_csv('test_final_fixed.tsv', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN trong train_data:\n",
      "sentence     0\n",
      "aspect       2\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "NaN trong test_data:\n",
      "sentence     0\n",
      "aspect       1\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file train và test\n",
    "train_data = pd.read_csv('train_final_fixed.tsv', sep='\\t', header=None, names=['sentence', 'aspect', 'sentiment'])\n",
    "test_data = pd.read_csv('test_final_fixed.tsv', sep='\\t', header=None, names=['sentence', 'aspect', 'sentiment'])\n",
    "\n",
    "# Kiểm tra xem có giá trị NaN nào không\n",
    "print(\"NaN trong train_data:\")\n",
    "print(train_data.isna().sum())\n",
    "\n",
    "print(\"NaN trong test_data:\")\n",
    "print(test_data.isna().sum())\n",
    "\n",
    "# Loại bỏ các hàng chứa NaN nếu có\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Lưu lại dữ liệu đã xử lý\n",
    "train_data.to_csv('train_final_cleaned.tsv', sep='\\t', index=False, header=False)\n",
    "test_data.to_csv('test_final_cleaned.tsv', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset NaN values:\n",
      " sentence     0\n",
      "aspect       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "Test dataset NaN values:\n",
      " sentence     0\n",
      "aspect       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv('train_final_cleaned.tsv', sep='\\t', header=None, names=['sentence', 'aspect', 'sentiment'])\n",
    "test_data = pd.read_csv('test_final_cleaned.tsv', sep='\\t', header=None, names=['sentence', 'aspect', 'sentiment'])\n",
    "\n",
    "# Check for NaN values in the train and test datasets\n",
    "train_nan = train_data.isna().sum()\n",
    "test_nan = test_data.isna().sum()\n",
    "\n",
    "print(\"Train dataset NaN values:\\n\", train_nan)\n",
    "print(\"Test dataset NaN values:\\n\", test_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khía cạnh: Sản phẩm - Sentiment: positive\n",
      "Khía cạnh: hàng - Sentiment: negative\n",
      "Khía cạnh: gia - Sentiment: negative\n",
      "Khía cạnh: giao - Sentiment: negative\n",
      "Khía cạnh: giao hàng - Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Đường dẫn tới file từ điển khía cạnh\n",
    "ASPECT_DICT_PATH = 'aspect_dict.txt'  # Thay đổi đường dẫn nếu cần thiết\n",
    "\n",
    "# Hàm đọc từ điển khía cạnh từ file\n",
    "def load_aspect_dict(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        aspect_keywords = f.read().splitlines()\n",
    "    return set(aspect_keywords)  # Chuyển thành set để dễ kiểm tra từ khóa\n",
    "\n",
    "# Load từ điển khía cạnh\n",
    "aspect_dict = load_aspect_dict(ASPECT_DICT_PATH)\n",
    "\n",
    "# Load PhoBERT tokenizer và model đã huấn luyện\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"D:/ABSAPhoBert/train_model\")  # Đường dẫn thư mục lưu mô hình sau khi huấn luyện\n",
    "model.eval()  # Đặt model vào chế độ evaluation (đánh giá)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Hàm để mã hóa và dự đoán sentiment cho một khía cạnh\n",
    "def predict_sentiment(sentence, aspect):\n",
    "    modified_sentence = f\"Về khía cạnh {aspect}, {sentence}\"\n",
    "    inputs = tokenizer.encode_plus(modified_sentence, aspect, add_special_tokens=True, truncation=True, max_length=256, padding=\"max_length\", return_tensors=\"pt\", truncation_strategy='only_first')\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Sử dụng từ điển khía cạnh để xác định khía cạnh trong câu\n",
    "def identify_aspects(sentence, aspect_dict):\n",
    "    identified_aspects = []\n",
    "    for keyword in aspect_dict:\n",
    "        if keyword in sentence:\n",
    "            identified_aspects.append(keyword)\n",
    "    return identified_aspects\n",
    "\n",
    "# Hàm để dự đoán sentiment cho các khía cạnh được nhận diện\n",
    "def predict_sentiment_for_identified_aspects(sentence, aspect_dict):\n",
    "    aspects = identify_aspects(sentence, aspect_dict)\n",
    "    results = {}\n",
    "    for aspect in aspects:\n",
    "        predicted_class = predict_sentiment(sentence, aspect)\n",
    "        \n",
    "        if predicted_class == 0:\n",
    "            sentiment = \"negative\"\n",
    "        elif predicted_class == 1:\n",
    "            sentiment = \"neutral\"\n",
    "        else:\n",
    "            sentiment = \"positive\"\n",
    "        \n",
    "        results[aspect] = sentiment\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Ví dụ câu cần phân tích\n",
    "sentence = \"Sản phẩm tốt nhưng giao hàng chậm\"\n",
    "\n",
    "# Dự đoán sentiment cho các khía cạnh được nhận diện\n",
    "predicted_sentiments = predict_sentiment_for_identified_aspects(sentence, aspect_dict)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "for aspect, sentiment in predicted_sentiments.items():\n",
    "    print(f\"Khía cạnh: {aspect} - Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Nếu trả về True, bạn đang dùng GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\huynh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\huynh\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: --sentence sản phẩm chính hãng và khá là ưa dùng\n",
      "Prediction for aspect ('sản phẩm'): Positive\n",
      "Extracted aspect: giao hàng\n",
      "Combined phrases: shipper giao hàng rất chậm\n",
      "Prediction for aspect ('giao hàng'): Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file tích hợp\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm chính hãng và khá là ưa dùng nhưng shipper giao hàng rất chậm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: shipper\n",
      "Combined phrases: shipper thân thiện\n",
      "Prediction for aspect ('shipper'): Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Shipper thân thiện\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: shipper\n",
      "Combined phrases: --sentence shipper khá là khó chịu và gây khó dễ cho người dùng\n",
      "Prediction for aspect ('shipper'): Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file tích hợp\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Shipper khá là khó chịu và gây khó dễ cho người dùng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: hàng\n",
      "Combined phrases: --sentence hàng tốt\n",
      "Prediction for aspect ('hàng'): Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file tích hợp\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Hàng tốt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: giao hàng\n",
      "Combined phrases: --sentence giao hàng chậm\n",
      "Prediction for aspect ('giao hàng'): Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file tích hợp\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"giao hàng chậm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: dùng\n",
      "Combined phrases: --sentence dùng tốt\n",
      "Prediction for aspect ('dùng'): Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file tích hợp\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"dùng tốt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sử dụng\n",
      "Combined phrases: sử dụng rất ổn định\n",
      "Prediction for aspect ('sử dụng'): Positive\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sử dụng rất ổn định\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: sản phẩm sử dụng rất ổn định\n",
      "Prediction for aspect ('sản phẩm'): Positive\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm sử dụng rất ổn định\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file tích hợp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined phrases: --sentence sản phẩm dùng khá ổn\n",
      "Prediction for aspect ('sản phẩm'): Positive\n",
      "Extracted aspect: thời gian giao hàng\n",
      "Combined phrases: thời gian giao hàng khá lâu\n",
      "Prediction for aspect ('thời gian giao hàng'): Negative\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm dùng khá ổn nhưng thời gian giao hàng khá lâu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: hộp điện thoại\n",
      "Combined phrases: hộp điện thoại đã bị khui\n",
      "Prediction for aspect ('hộp điện thoại'): Negative\n",
      "Extracted aspect: chăm sóc khách hàng\n",
      "Combined phrases: chăm sóc khách hàng chưa tốt\n",
      "Prediction for aspect ('chăm sóc khách hàng'): Negative\n",
      "Extracted aspect: sử dụng\n",
      "Combined phrases: một số máy bị đơ và nóng khi sử dụng\n",
      "Prediction for aspect ('sử dụng'): Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\git hub desktop\\ABSA-PhoBert-and-Bayes\\infer_example.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))  # Tải trọng số từ file tích hợp\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Một số trường hợp không được đồng kiểm, hộp điện thoại đã bị khui, chăm sóc khách hàng chưa tốt. Một số máy bị đơ và nóng khi sử dụng.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: hộp điện thoại\n",
      "Combined phrases: --sentence hộp điện thoại đã bị khui\n",
      "Prediction for aspect ('hộp điện thoại'): Negative\n",
      "Extracted aspect: chăm sóc khách hàng\n",
      "Combined phrases: chăm sóc khách hàng chưa tốt\n",
      "Prediction for aspect ('chăm sóc khách hàng'): Negative\n",
      "Extracted aspect: sử dụng\n",
      "Combined phrases: một số máy bị đơ và nóng khi sử dụng\n",
      "Prediction for aspect ('sử dụng'): Negative\n",
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: sản phẩm còn new seal\n",
      "Prediction for aspect ('sản phẩm'): Neutral\n",
      "Extracted aspect: phần mềm\n",
      "Combined phrases: mình đã từng dùng cả xiao mi và samsung thì thấy samsung phần mềm ổn định\n",
      "Prediction for aspect ('phần mềm'): Positive\n",
      "Extracted aspect: dùng\n",
      "Combined phrases: dễ dùng hơn\n",
      "Prediction for aspect ('dùng'): Positive\n",
      "Extracted aspect: phần cứng\n",
      "Combined phrases: phần cứng bền bỉ hơn và không bị nóng máy\n",
      "Prediction for aspect ('phần cứng'): Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"hộp điện thoại đã bị khui, chăm sóc khách hàng chưa tốt. Một số máy bị đơ và nóng khi sử dụng. Sản phẩm còn new seal. Mình đã từng dùng cả Xiao Mi và Samsung thì thấy Samsung phần mềm ổn định, dễ dùng hơn, ít lỗi vặt hơn, phần cứng bền bỉ hơn và không bị nóng máy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: --sentence sản phẩm không quá mắc tiền\n",
      "Prediction for aspect ('sản phẩm'): Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm không quá mắc tiền\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: --sentence sản phẩm bình thường\n",
      "Prediction for aspect ('sản phẩm'): Neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm bình thường\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: --sentence sản phẩm chính hãng\n",
      "Prediction for aspect ('sản phẩm'): Neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm chính hãng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: sản phẩm tệ\n",
      "Prediction for aspect ('sản phẩm'): Negative\n",
      "Extracted aspect: sử dụng\n",
      "Combined phrases: theo đó là sử dụng cũng rất là chán\n",
      "Prediction for aspect ('sử dụng'): Negative\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm tệ song theo đó là sử dụng cũng rất là chán\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: sản phẩm tốt\n",
      "Prediction for aspect ('sản phẩm'): Positive\n",
      "Extracted aspect: sử dụng\n",
      "Combined phrases: dễ sử dụng\n",
      "Prediction for aspect ('sử dụng'): Positive\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm tốt, chính hãng, dễ sử dụng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: sản phẩm ở mức khá\n",
      "Prediction for aspect ('sản phẩm'): Neutral\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm ở mức khá\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: sản phẩm tạm được\n",
      "Prediction for aspect ('sản phẩm'): Neutral\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Sản phẩm tạm được\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: giao hàng\n",
      "Combined phrases: giao hàng nhanh\n",
      "Prediction for aspect ('giao hàng'): Positive\n",
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: sản phẩm không tốt\n",
      "Prediction for aspect ('sản phẩm'): Negative\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Giao hàng nhanh nhưng sản phẩm không tốt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted aspect: sản phẩm\n",
      "Combined phrases: --sentence tôi cảm thấy khá là may mắn khi mua được sản phẩm này\n",
      "Prediction for aspect ('sản phẩm'): Positive\n",
      "Extracted aspect: trải nghiệm\n",
      "Combined phrases: đối với việc phải trải qua những sản phẩm dễ bị hư trong quá khứ tôi đã được trải nghiệm sản phẩm mới và khá chất lượng\n",
      "Prediction for aspect ('trải nghiệm'): Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python infer_example.py --sentence \"Tôi cảm thấy khá là may mắn khi mua được sản phẩm này, đối với việc phải trải qua những sản phẩm dễ bị hư trong quá khứ tôi đã được trải nghiệm sản phẩm mới và khá chất lượng\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
